---
title: "Are Bayern Munich Good or is the Bundesliga Bad? Measuring Performance Conditional on Resources Using a Bayesian Multilevel Regression"
author: "Paul Johnson"
format: html
editor_options: 
  chunk_output_type: console
---

```{r setup}
suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
  library(rstanarm)
  library(brms)
})

theme_set(theme_minimal())

club_resources <- readr::read_rds(here::here("data", "club_resources.rds"))

```

# Exploratory Data Analysis

```{r pts}

club_resources %>%
  ggplot(aes(pts)) +
  geom_histogram()

club_resources %>%
  ggplot(aes(pts, fill = league)) +
  geom_histogram() +
  scale_fill_viridis_d()

club_resources %>%
  ggplot(aes(pts, fill = league)) +
  geom_histogram(binwidth = 5) +
  scale_fill_viridis_d() +
  facet_wrap(~ league)

```

```{r squad-values}
# comparing squad values in each league over time
club_resources %>%
  group_by(league, season) %>%
  summarise(value = median(value)) %>%
  ggplot(aes(season, value, group = league, fill = league)) +
  geom_col(position = "dodge") +
  scale_fill_viridis_d()
```

```{r transfer-spending}

club_resources %>%
  filter(season != 2022) %>%
  ggplot(aes(pts, net_spend, colour = league)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_colour_viridis_d() +
  scale_y_continuous(labels = scales::label_comma()) +
  facet_wrap(~ league)
```

-   The number of players seems to have a negative correlation with points (this is itself relatively interesting), but I suspect it is a relevant control variable.

```{r squad-size}

club_resources %>%
  filter(season != 2022) %>%
  ggplot(aes(pts, num_players)) +
  geom_point() +
  geom_smooth(method = "lm")

club_resources %>%
  filter(season != 2022) %>%
  ggplot(aes(pts, num_players, colour = league)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_colour_viridis_d()

club_resources %>%
  filter(season != 2022) %>%
  ggplot(aes(pts, num_players, colour = league)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_colour_viridis_d() +
  facet_wrap(~ league)

```

-   The number of games missed through injury is clearly a function of the number of games a team plays each season, and because the injury data appears to include **all** games missed, not just league games, there is a positive relationship between points and games missed to injury.
-   As a result, I've used days_injured instead, which is an imperfect measure of the effect injuries have on a team, but at least will not be a function of a team's success in non-league competitions.

```{r injuries}

club_resources %>%
  filter(season != 2022) %>%
  ggplot(aes(pts, days_injured/num_players, colour = league)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_colour_viridis_d() +
  facet_wrap(~ league)

```

-   One of the most noticeable details that you can identify from the EDA is that there appears to be not only a different intercept for each league, but also the slope differs too. This is not entirely surprising, but it wasn't my initial working assumption. I was starting from an assumption that the differences would be based on leagues having different intercepts.

-   Is there also a non-linear trend in certain leagues? There does look like there might be an exponential relationship between market value and points. This may exist across all leagues, it's just that some league don't have such large disparities that that trend shows up?

-   I need to facet the leagues to look at them individually as well.

-   When log-transformed, there doesn't appear to be a massive difference in the slopes of each league, except for the Austrian Bundesliga, and Ligue 1. However, I'm not sure the difference is big enough to make it worth modelling varying slopes.

```{r pts-and-values}
  
club_resources %>%
  ggplot(aes(pts, log(value), colour = league)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_colour_viridis_d() +
  scale_y_continuous(labels = scales::label_comma())

club_resources %>%
  ggplot(aes(pts, log(value), colour = league)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_colour_viridis_d() +
  scale_y_continuous(labels = scales::label_comma()) +
  facet_wrap(~ league)

```

# Preparing Data for Modelling

-   Some basic transformations and type changes of variables to make sure the data is ready for modelling

```{r data-prep}

club_resources <-
  club_resources %>%
  mutate(
    weighted_injuries = days_injured/num_players,
    log_value = log(value)
  )

model_df <- 
  club_resources %>%
  mutate(
    league = forcats::as_factor(league),
    season = forcats::as_factor(season),
    squad = forcats::as_factor(squad),
    log_value = (log_value - mean(log_value))/sd(log_value),
    value = (value - mean(value))/sd(value),
    pts = (pts - mean(pts))/sd(pts),
    net_spend = (net_spend - mean(net_spend))/sd(net_spend),
    num_players = (num_players - mean(num_players))/sd(num_players),
    days_injured = (days_injured - mean(days_injured))/sd(days_injured),
    weighted_injuries = (weighted_injuries - mean(weighted_injuries))/sd(weighted_injuries)
    )

```

# Regression Models as Building Blocks

## Simple Linear Model with Squad Value Predictor

```{r simple-glm}

value_glm <- stan_glm(pts ~ log_value, data = model_df)

summary(value_glm)

value_R2 <- loo_R2(value_glm)

median(value_R2)

as_tibble(value_R2) %>%
  ggplot(aes(value)) +
  geom_density()

```

The Loo $R^2$ is much better for the regression including squad values than the intercept only regression. This is to be expected, but it does help to check these things!

The multivariate regression including all potential explanatory variables is also a little better than the model that only contains the squad values as a predictor.  The improvement isn't huge, but it's significant enough to suggest there's value in including some of those variables.

## Multivariable Linear Model

```{r multivariable-glm}

multivariable_glm <- stan_glm(pts ~ value + days_injured + num_players, data = model_df)

summary(multivariate_glm)

multivariate_R2 <- loo_R2(multivariate_glm)

median(multivariate_R2)

as_tibble(multivariate_R2) %>%
  ggplot(aes(value)) +
  geom_density()

```

We can also carry out some diagnostic checks and some posterior predictive checks.

```{r glm-diagnostics}

bayesplot::mcmc_trace(multivariate_glm)

bayesplot::ppc_dens_overlay(
  y = multivariate_glm$y,
  yrep = posterior_predict(
    multivariate_glm,
    draws = 50
    )
)

```

```{r glm-estimates}
bayestestR::hdi(
  multivariate_glm,
  ci = c(
    0.5, 0.75, 0.89, 0.95
    )
  ) %>%
  plot()

multivariate_posterior <- as.matrix(multivariate_glm)

bayestestR::map_estimate(
  multivariate_posterior
  ) %>%
  plot()

```

# Hierarchical Modelling Structures

## Varying Intercepts Model with No Predictors

-   So the log(value) models perform slightly worse than the non-transformed models, in terms of $Loo R^2$. Is this because there is less variance to explain? I'm not sure what to make of this issue...

```{r no-predictors}

no_predictors_lmer <-
  stan_lmer(pts ~ 1 + (1 | league),
      data = model_df)  

summary(no_predictors_lmer)

no_predictors_R2 <- loo_R2(no_predictors_lmer)

as_tibble(no_predictors_R2) %>%
  ggplot(aes(value)) +
  geom_density()

```

## Varying Intercepts Model with Squad Value Predictor

```{r value-varying-intercepts}

varying_intercepts_lmer <- 
  stan_lmer(pts ~ value + (1|league), data = model_df)

bayesplot::mcmc_trace(varying_intercepts_lmer)
```

## Varying Intercepts & Slopes Model

```{r varying-intercepts-slopes}

varying_intercepts_slopes_lmer <- 
  stan_lmer(pts ~ log_value + league + (1|league), data = model_df)

bayesplot::mcmc_trace(varying_intercepts_slopes_lmer)

bayesplot::ppc_dens_overlay(
  y = varying_intercepts_slopes_lmer$y,
  yrep = posterior_predict(
    varying_intercepts_slopes_lmer,
    draws = 50
    )
)
```

## Varying Intercepts Model with Multiple Predictors

```{r multivariable-varying-intercepts}

multivariable_varying_intercepts_lmer <- 
  stan_lmer(pts ~ log_value + weighted_injuries + (1|league), data = model_df)

bayesplot::mcmc_trace(multivariable_varying_intercepts_lmer)

bayesplot::ppc_dens_overlay(
  y = multivariable_varying_intercepts_lmer$y,
  yrep = posterior_predict(
    multivariable_varying_intercepts_lmer,
    draws = 50
    )
)

prior_summary(multivariable_varying_intercepts_lmer)

print(multivariable_varying_intercepts_lmer, digits = 2)
```

# Simulating Bundesliga Points Total Based on Club Resources

```{r sims}

```
